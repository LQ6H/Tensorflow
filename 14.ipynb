{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow搭建神经网络的主要函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "梳理利用Tensorflow搭建神经网络的整个过程中使用的主要函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 一.第1步：网络的输入\n",
    "神经网络的输入可以利用占位符声明"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.占位符"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.placeholder(dtype,shape=None,name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二.第2步：搭建网络\n",
    "如果搭建的是全连接神经网络，则主要使用矩阵乘法和加法的函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.矩阵乘法函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.matmul(a,b,transpose_a=False,transpose_b=False,adjoint_a=False,adjoint_b=False,a_is_sparse=False,b_is_sparse=False,name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.加法函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.add(x,y,name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果搭建的是卷积神经网络，则主要使用卷积函数，池化函数和加法函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.卷积函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.nn.conv2d(input,filter,strides,padding,use_cudnn_on_gpu=True,data_format='NHWC',dilations=[1,1,1,1],name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.池化函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.nn.max_pool(value,ksize,strides,padding,data_format='NHWC',name=None)\n",
    "tf.nn.avg_pool(value,ksize,strides,padding,data_format='NHWC',name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "加法函数和搭建全连接神经网络使用的加法函数相同。当然可以直接使用加法运算符\"+\"\n",
    "为了防止过拟合，可以添加dropout操作，对应的函数如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.nn.dropout(x,keep_prob,noise_shape=None,seed=None,name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了加快收敛速度，可以添加BN操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.moments(x,axes,shitf=None)\n",
    "tf.nn.batch_normalization(x,mean,variance,offset,scale,variance_epsilon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "搭建神经网络使用如下激活函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.nn.sigmoid(x,name=None)\n",
    "tf.nn.tanh(x,name=None)\n",
    "tf.nn.relu(features,name=None)\n",
    "tf.nn.relu6(features,alpha=0.2,name=None)\n",
    "tf.nn.crelu(features,name=None)\n",
    "tf.nn.selu(features,name=None)\n",
    "tf.nn.softplus(features,name=None)\n",
    "r=tf.nn.softsign(features,name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 三.第3步：创建损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reduce_sum(input_tensor,axis=None,keepdims=None,name=None,reduction_indices=None,keep_dims=None)\n",
    "tf.nn.sigmoid_cross_entropy_with_logits(abels=None,logits=None)\n",
    "tf.nn.softmax_cross_entropy_with_logits_2(abels=None,logits=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 四.第4步：选择优化器(即梯度下降法)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.train.GradientDescentOptimizer\n",
    "tf.train.AdagradOptimizer\n",
    "tf.train.MomentumOptimizer\n",
    "tf.train.RMSPropOptimizer\n",
    "tf.train.AdadeltaOptimizer\n",
    "tf.train.AdamOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 五.第5步：评估模型的准确率\n",
    "评估模型的准确率就是对比人工分类和模型分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.equal(x,y,name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用对比函数，返回值是bool型，所以需要类型转换函数："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.cast(x,dtype,name=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后根据cast的返回值，利用平均值函数tf.reduce_mean(input_tensor,axis=None)计算准确率(百分比)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 六.第6步：保存和加载模型\n",
    "训练模型结束后，需要保存模型，创建类tf.train.Saver，然后利用成员函数save()保存模型\n",
    "模型加载时，利用其成员函数restore()加载到内存中"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
