{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow--神经网络处理分类问题"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 一.TFRecord文件\n",
    "TFRecord是Tensorflow设计的一种存储数据的内置文件格式，可以方便高效地管理数据及这些数据的相关信息，利用它可以将数据快速加载到内存中。接下来介绍如何将数据写入TFRecord文件和从TFRecord中解析数据的过程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.将ndarray写入TFRecord文件\n",
    "假设有3个三维的ndarray，尺寸依次为2行3列4深度，3行3列3深度和2行2列3深度。将这3个ndarray及其对应的尺寸(高，宽，深度)写入文件名为data1.tfrecord的TFRecord文件中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 创建文件\n",
    "record=tf.python_io.TFRecordWriter(\"dataTest1.tfrecord\")\n",
    "\n",
    "# 高为2，宽为3，深度为4的三维ndarray\n",
    "array1=np.array(\n",
    "    [\n",
    "        [[1,2,1,2],[3,4,2,9],[5,6,0,3]],\n",
    "        [[7,8,1,6],[9,6,1,7],[1,2,5,9]]\n",
    "    ]\n",
    "    ,np.float32\n",
    ")\n",
    "\n",
    "# 高为3，宽为3，深度为3的三维ndarray\n",
    "array2=np.array(\n",
    "    [\n",
    "        [[11,12,11],[13,14,12],[15,16,13]],\n",
    "        [[17,18,11],[19,10,11],[11,12,15]],\n",
    "        [[13,14,15],[18,11,12],[19,14,10]]\n",
    "    ]\n",
    "    ,np.float32\n",
    ")\n",
    "\n",
    "# 高为2，宽为2，深度为3的三维ndarray\n",
    "array3=np.array(\n",
    "    [\n",
    "        [[21,23,21],[23,24,22]],\n",
    "        [[27,28,24],[29,20,21]]\n",
    "    ]\n",
    "    ,np.float32\n",
    ")\n",
    "\n",
    "# 将上述3个ndarray存入一个列表\n",
    "arrays=[array1,array2,array3]\n",
    "\n",
    "# 循环处理上述列表中的每一个ndarray\n",
    "for array in arrays:\n",
    "    # 计算每一个ndarray的形状\n",
    "    height,width,depth=array.shape\n",
    "    # 将ndarray中的值转为字节类型\n",
    "    array_raw=array.tostring()\n",
    "    # ndarray的值及对应的高，宽及深度\n",
    "    feature={\n",
    "        'array_raw':\n",
    "            tf.train.Feature(\n",
    "                bytes_list=tf.train.BytesList(value=[array_raw])\n",
    "            ),\n",
    "        'height':\n",
    "            tf.train.Feature(int64_list=tf.train.Int64List(value=[height])),\n",
    "        'width':\n",
    "            tf.train.Feature(int64_list=tf.train.Int64List(value=[width])),\n",
    "        'depth':\n",
    "            tf.train.Feature(int64_list=tf.train.Int64List(value=[depth]))\n",
    "    }\n",
    "    \n",
    "    features=tf.train.Features(feature=feature)\n",
    "    example=tf.train.Example(features=features)\n",
    "    # 字符串序列化后写入文件\n",
    "    record.write(example.SerializeToString())\n",
    "    \n",
    "record.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上述程序中，首先得到每一个ndarray的高，宽和深度，然后利用ndarray的成员函数tostring()将ndarray转换为字节类型，并将这些数据存储在tf.train.Example对象中，再利用其成员函数SerializeToString()序列化为二进制字符串，最后利用TFRecordWriter对象的成员函数Write将序列化后的二进制字符串写入TFRecord文件中"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.从TFRecord解析数据\n",
    "首先利用函数tr.train.string_input_producer读取一个TFRecord文件列表，然后创建一个TFRecordReader对象，利用其成员函数读取TFRecord文件列表，最后利用函数tf,parse_single_example解析文件中的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---第1次解析到的ndarray---\n",
      "[ 1.  2.  1.  2.  3.  4.  2.  9.  5.  6.  0.  3.  7.  8.  1.  6.  9.  6.\n",
      "  1.  7.  1.  2.  5.  9.]\n",
      "---第2次解析到的ndarray---\n",
      "[ 11.  12.  11.  13.  14.  12.  15.  16.  13.  17.  18.  11.  19.  10.  11.\n",
      "  11.  12.  15.  13.  14.  15.  18.  11.  12.  19.  14.  10.]\n",
      "---第3次解析到的ndarray---\n",
      "[ 21.  23.  21.  23.  24.  22.  27.  28.  24.  29.  20.  21.]\n",
      "---第4次解析到的ndarray---\n",
      "[ 1.  2.  1.  2.  3.  4.  2.  9.  5.  6.  0.  3.  7.  8.  1.  6.  9.  6.\n",
      "  1.  7.  1.  2.  5.  9.]\n",
      "---第5次解析到的ndarray---\n",
      "[ 11.  12.  11.  13.  14.  12.  15.  16.  13.  17.  18.  11.  19.  10.  11.\n",
      "  11.  12.  15.  13.  14.  15.  18.  11.  12.  19.  14.  10.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 读取tfrecord文件列表\n",
    "record_queue=tf.train.string_input_producer(['dataTest1.tfrecord'],num_epochs=2)\n",
    "\n",
    "# 创建一个TFRecordReader对象\n",
    "reader=tf.TFRecordReader()\n",
    "_,serialized_example=reader.read(record_queue)\n",
    "\n",
    "# j解析tfrecord中的数据，每次只解析一个\n",
    "features=tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={\n",
    "        'array_raw':tf.FixedLenFeature([],tf.string),\n",
    "        'height':tf.FixedLenFeature([],tf.int64),\n",
    "        'width':tf.FixedLenFeature([],tf.int64),\n",
    "        'depth':tf.FixedLenFeature([],tf.int64)\n",
    "    }\n",
    ")\n",
    "\n",
    "# 解析出对应的值\n",
    "array_raw=features['array_raw']\n",
    "array=tf.decode_raw(array_raw,tf.float32) # 解码\n",
    "height=features['height']\n",
    "width=features['width']\n",
    "depth=features['depth']\n",
    "\n",
    "# 创建会话\n",
    "session=tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "session.run(tf.local_variables_initializer())\n",
    "coord=tf.train.Coordinator()\n",
    "threads=tf.train.start_queue_runners(sess=session,coord=coord)\n",
    "\n",
    "# 循环5次解析文件流中的数据\n",
    "for i in range(5):\n",
    "    ndarray,h,w,d=session.run([array,height,width,depth])\n",
    "    print(\"---第%(num)d次解析到的ndarray---\"%{\"num\":i+1})\n",
    "    print(ndarray)\n",
    "    \n",
    "coord.request_stop()\n",
    "coord.join(threads)\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从打印结果可以看出，解析出的每个ndarray都是一维的，这是因为在写入文件时，首先将原数据转换为字节类型。当然我们也可以根据解析到的每个ndarray对应的高，宽和深度将其转换为三维的ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---第1次解析到ndarray---\n",
      "[[[ 1.  2.  1.  2.]\n",
      "  [ 3.  4.  2.  9.]\n",
      "  [ 5.  6.  0.  3.]]\n",
      "\n",
      " [[ 7.  8.  1.  6.]\n",
      "  [ 9.  6.  1.  7.]\n",
      "  [ 1.  2.  5.  9.]]]\n",
      "---第2次解析到ndarray---\n",
      "[[[ 11.  12.  11.]\n",
      "  [ 13.  14.  12.]\n",
      "  [ 15.  16.  13.]]\n",
      "\n",
      " [[ 17.  18.  11.]\n",
      "  [ 19.  10.  11.]\n",
      "  [ 11.  12.  15.]]\n",
      "\n",
      " [[ 13.  14.  15.]\n",
      "  [ 18.  11.  12.]\n",
      "  [ 19.  14.  10.]]]\n",
      "---第3次解析到ndarray---\n",
      "[[[ 21.  23.  21.]\n",
      "  [ 23.  24.  22.]]\n",
      "\n",
      " [[ 27.  28.  24.]\n",
      "  [ 29.  20.  21.]]]\n",
      "---第4次解析到ndarray---\n",
      "[[[ 1.  2.  1.  2.]\n",
      "  [ 3.  4.  2.  9.]\n",
      "  [ 5.  6.  0.  3.]]\n",
      "\n",
      " [[ 7.  8.  1.  6.]\n",
      "  [ 9.  6.  1.  7.]\n",
      "  [ 1.  2.  5.  9.]]]\n",
      "---第5次解析到ndarray---\n",
      "[[[ 11.  12.  11.]\n",
      "  [ 13.  14.  12.]\n",
      "  [ 15.  16.  13.]]\n",
      "\n",
      " [[ 17.  18.  11.]\n",
      "  [ 19.  10.  11.]\n",
      "  [ 11.  12.  15.]]\n",
      "\n",
      " [[ 13.  14.  15.]\n",
      "  [ 18.  11.  12.]\n",
      "  [ 19.  14.  10.]]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 读取tfrecord文件列表\n",
    "record_queue=tf.train.string_input_producer(['dataTest1.tfrecord'],num_epochs=2)\n",
    "\n",
    "# 创建一个TFRecordReader对象\n",
    "reader=tf.TFRecordReader()\n",
    "_,serialized_example=reader.read(record_queue)\n",
    "\n",
    "# j解析tfrecord中的数据，每次只解析一个\n",
    "features=tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={\n",
    "        'array_raw':tf.FixedLenFeature([],tf.string),\n",
    "        'height':tf.FixedLenFeature([],tf.int64),\n",
    "        'width':tf.FixedLenFeature([],tf.int64),\n",
    "        'depth':tf.FixedLenFeature([],tf.int64)\n",
    "    }\n",
    ")\n",
    "\n",
    "# 解析出对应的值\n",
    "array_raw=features['array_raw']\n",
    "array=tf.decode_raw(array_raw,tf.float32) # 解码\n",
    "height=features['height']\n",
    "width=features['width']\n",
    "depth=features['depth']\n",
    "\n",
    "# 创建会话\n",
    "session=tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "session.run(tf.local_variables_initializer())\n",
    "coord=tf.train.Coordinator()\n",
    "threads=tf.train.start_queue_runners(sess=session,coord=coord)\n",
    "\n",
    "# 循环5次解析文件流中的数据\n",
    "for i in range(5):\n",
    "    ndarray,h,w,d=session.run([array,height,width,depth])\n",
    "    ndarray=np.reshape(ndarray,[h,w,d])\n",
    "    print('---第%(num)d次解析到ndarray---'%{'num':i+1})\n",
    "    print(ndarray)\n",
    "    \n",
    "coord.request_stop()\n",
    "coord.join(threads)\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从TFRecord文件中随机解析数据\n",
    "假设有3个尺寸同为1行2列3深度的ndarray，写入文件名为data2.tfrecord的TFRecord文件中，因为已经知道这3个ndarray的尺寸都是1行2列3深度，所以一般只存储原数据即可，不存储其高，宽，深度等信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "record=tf.python_io.TFRecordWriter(\"dataTest2.tfrecord\")\n",
    "\n",
    "array1=np.array(\n",
    "    [\n",
    "        [[1,2,3],[4,5,6]],\n",
    "    ]\n",
    "    ,np.float32\n",
    ")\n",
    "\n",
    "array2=np.array(\n",
    "    [\n",
    "        [[11,12,13],[14,15,16]],\n",
    "    ]\n",
    "    ,np.float32\n",
    ")\n",
    "\n",
    "array3=np.array(\n",
    "    [\n",
    "        [[21,23,21],[23,24,22]],\n",
    "    ]\n",
    "    ,np.float32\n",
    ")\n",
    "\n",
    "arrays=[array1,array2,array3]\n",
    "\n",
    "for array in arrays:\n",
    "    array_raw=array.tostring()\n",
    "    \n",
    "    feature={\n",
    "        'array_raw':\n",
    "            tf.train.Feature(\n",
    "                bytes_list=tf.train.BytesList(value=[array_raw])\n",
    "            ),\n",
    "    }\n",
    "    \n",
    "    features=tf.train.Features(feature=feature)\n",
    "    example=tf.train.Example(features=features)\n",
    "    \n",
    "    record.write(example.SerializeToString())\n",
    "record.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 创建一个TFRecordReader对象\n",
    "epochs=2\n",
    "reader=tf.TFRecordReader()\n",
    "record_queue=tf.train.string_input_producer(['dataTest2.tfrecord'],num_epochs=epochs)\n",
    "\n",
    "_,serialized_example=reader.read(record_queue)\n",
    "\n",
    "# 解析文件中的图像及其对应的标签\n",
    "features=tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={\n",
    "        'array_raw':tf.FixedLenFeature([],tf.string)\n",
    "    }\n",
    ")\n",
    "\n",
    "# 解码二进制数据\n",
    "array_raw=features['array_raw']\n",
    "array_raw=tf.decode_raw(array_raw,tf.float32) # 解码\n",
    "array=tf.reshape(array_raw,[1,2,3])\n",
    "\n",
    "# 每次从文件中读取2个数据\n",
    "BatchSize=2\n",
    "arrays=tf.train.shuffle_batch([array],BatchSize,1000+3*BatchSize,1000)\n",
    "\n",
    "# 创建会话\n",
    "session=tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "session.run(tf.local_variables_initializer())\n",
    "coord=tf.train.Coordinator()\n",
    "threads=tf.train.start_queue_runners(sess=session,coord=coord)\n",
    "\n",
    "# 循环2次,从文件中随机读取\n",
    "for i in range(2):\n",
    "    arrs=session.run([arrays])\n",
    "    print('---第%(num)d次解析到ndarray---'%{'num':i+1})\n",
    "    print(arrs)\n",
    "    \n",
    "coord.request_stop()\n",
    "coord.join(threads)\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 二.建立分类问题的数学模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.数据类别\n",
    "Tensorflow通过函数one_hot实现类别的数字化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  1.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  1.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  1.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "v=tf.one_hot([9,2,7,3,0,4,8,6,1,3,4,8,6,1],depth=10,axis=1,dtype=tf.float32)\n",
    "\n",
    "session=tf.Session()\n",
    "\n",
    "print(session.run(v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "以上代码中，函数one_hot中的参数depth=10代表有10个类别，axis代表按照每一行存储类别的数字化，因为有10类，所以返回结果有10列"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 2.0图像与TFRecord\n",
    "将ndarray写入TFRecord的方法，分别将每一个文件夹下的数字图像保存到一个TFRecord文件中，代码如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.image as mp_image\n",
    "\n",
    "N=10\n",
    "\n",
    "for label in range(N):\n",
    "    record=tf.python_io.TFRecordWriter(os.path.curdir+'/data/'+'data%(label)d.tfrecord'%{'label':label})\n",
    "    curDir=os.path.curdir+'/data/'+str(label)+'/'\n",
    "    fileList=os.listdir(curDir)\n",
    "    \n",
    "    for name in fileList:\n",
    "        # 图片的路径和名称\n",
    "        imagePath=curDir+name\n",
    "        # 读取图片，数字化为ndarray\n",
    "        image=mp_image.imread(imagePath)\n",
    "        # 将ndarray二进制化\n",
    "        img_raw=image.tostring()\n",
    "        \n",
    "        feature={\n",
    "            'img_raw':\n",
    "            tf.train.Feature(bytes_list=tf.train.BytesList(value=[img_raw])),\n",
    "            'label':\n",
    "            tf.train.Feature(int64_list=tf.train.Int64List(value=[label]))\n",
    "        }\n",
    "        \n",
    "        features=tf.train.Features(feature=feature)\n",
    "        example=tf.train.Example(features=features)\n",
    "        \n",
    "        # 字符串序列化后写入文件\n",
    "        record.write(example.SerializeToString())\n",
    "        \n",
    "    # 关闭文件流\n",
    "    record.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "介绍如何从这10个TFRecord文件中，每次随机读取3幅图片和对应的分类标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[b'.\\\\data\\\\data0.tfrecord' b'.\\\\data\\\\data1.tfrecord'\n",
      " b'.\\\\data\\\\data2.tfrecord' b'.\\\\data\\\\data3.tfrecord'\n",
      " b'.\\\\data\\\\data4.tfrecord' b'.\\\\data\\\\data5.tfrecord'\n",
      " b'.\\\\data\\\\data6.tfrecord' b'.\\\\data\\\\data7.tfrecord'\n",
      " b'.\\\\data\\\\data8.tfrecord' b'.\\\\data\\\\data9.tfrecord']\n",
      "---第1批图像---\n",
      "---第1批图像中的第1张：标签为2---\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEYpJREFUeJzt3X+QXWV9x/HPdzebDUlAEylpGvmR\nMJSCFIJdflgs4kQoFjvATMmQdmjstEamMq2VGWH4o2I7tWALgh1LJ0okTBWhI0haqUAzOECFmIUi\nxCaGH40QSbNgpCT82Gx2v/1jL84a9nyfmz33nHOT5/2ayezuffbc+83d/ezZu9/zPI+5uwDkp6fp\nAgA0g/ADmSL8QKYIP5Apwg9kivADmSL8QKYIP5Apwg9kalqdDzbd+n2GZlVz55YY50JGZOBNvabd\nPpxKg6SS4TezcyXdKKlX0lfc/Zro82dolk6zJWUesriWafF/xffsSdxBW89XNVKXWKdqi47v6Y2P\nHRut7rFTx6eOLVt7pMr/VzvHV2Sdr237c6f8a7+Z9Ur6kqQPSzpe0jIzO36q9wegXmVe858q6Rl3\nf87dd0v6hqTzO1MWgKqVCf8CSS9M+Hhr67ZfYGYrzGzQzAZHNFzi4QB0UpnwT/ai520vdNx9pbsP\nuPtAn/pLPByATioT/q2SDp/w8bslvViuHAB1KRP+9ZKOMbOFZjZd0sWS1nSmLABVm3Krz933mNll\nku7VeKtvlbv/sGOVTSJq5yVbeck7T/wcrLKtlDq8N255hf/3Jlt57RxfpahVWObreYAo1ed393sk\n3dOhWgDUiMt7gUwRfiBThB/IFOEHMkX4gUwRfiBTtc7nL8vHSvSMq5yyW+XUU3XgGoaATeuLH3s0\nUXuV1z8k7tv6pofjPrJ7Xytq3wGw0xVnfiBThB/IFOEHMkX4gUwRfiBThB/IVP2tvjKruUatn1S7\nLaVMy6rq6aGp/5uPBWPxc1q6HVZmSm9qGrXHz2uVrbxG24g14cwPZIrwA5ki/ECmCD+QKcIPZIrw\nA5ki/ECm6u3zW7wMdampq2V77Yl+dTT1NdnzTfXCK1w2vPc9x4bjQ6fPje8gUVpvYge2g35a/DXt\n//b6+ODU16TMkuaJ+z4Q+vgpnPmBTBF+IFOEH8gU4QcyRfiBTBF+IFOEH8hUqT6/mW2RtFPSqKQ9\n7j4QHuAle/kl1gJIzs9OLFFdqu+bqG3zTb8Rjh906OuJuy9+XpYctTk89l9/5bZwfI/i56Xf4qW/\n17w2s3Ds2pmXhMfO/pd14Xjyeyn6fim5lkBXb03epk5c5PNBd3+5A/cDoEb82g9kqmz4XdJ9ZvaY\nma3oREEA6lH21/4z3P1FMztM0v1mtsndH5z4Ca0fCiskaYaKX/8BqFepM7+7v9h6OyTpLkmnTvI5\nK919wN0H+tRf5uEAdNCUw29ms8zs4Lfel3SOpA2dKgxAtcr82j9P0l023vKYJunr7v6djlQFoHJT\nDr+7PyfppA7WUm59+oTS87NPP7Fw6I15M8JDX74k7tM/dfoXw/E+i5+XqNc+mnjOhj3ulQ/ujq+P\n6FV8/+fN3FU4dvr114fHXmiXh+Oz73g0HA977Yk+Puv2AzhgEX4gU4QfyBThBzJF+IFMEX4gU/Vv\n0R2pcqvrxBTMsTMXh+Mf/IfvFY5d8a6N8X0rnt7ZZ3Gr8IKnfzsc3/TdowvHvCcxtTTx43/uhsQW\n34nu7H9cc0Ph2OzEdOBTrhgMxzfdVV07rvRy7PvBlF7O/ECmCD+QKcIPZIrwA5ki/ECmCD+QKcIP\nZKq7+vxleqcl+65//dWvhOPHTS/u+w4llv2+9f9ODsf//cqzwvFZjz0fjh/5v8XXICSVfN56j//V\ncPz1YOrsnJ64z9/fE0839pFwuFpll/7uApz5gUwRfiBThB/IFOEHMkX4gUwRfiBThB/IVFf1+a03\nnhwebsmcmj+d6Gf//r/9aeL44qHZW+K6518X9+H7tT4cT25qHi15nlojIfW8JZZT3/a38fnjXT0H\nFY6ltv9+YzS+DkAq0egvu0x8lWtP1IQzP5Apwg9kivADmSL8QKYIP5Apwg9kivADmUr2+c1slaSP\nSBpy9xNat82VdLukoyRtkbTU3X/W1iMG/dWwj5+qs78/HPfh4XD8mD9bF9//tOKnqkzdHRH0nJNb\nTe+Je+W7fu+UcPyrJ94Yjo8F32KjiWsM/utz7w3HZyr+moXK9ulT1wnsB9cBtHPmv0XSuXvddqWk\nte5+jKS1rY8B7EeS4Xf3ByXt2Ovm8yWtbr2/WtIFHa4LQMWm+pp/nrtvk6TW28M6VxKAOlR+bb+Z\nrZC0QpJmaGbVDwegTVM98283s/mS1Ho7VPSJ7r7S3QfcfaBP8R/lANRnquFfI2l56/3lku7uTDkA\n6pIMv5ndJukRScea2VYz+2NJ10g628yelnR262MA+5Hka353X1YwtGRKj5iaJz1FqT5+2b5spb38\nsnu9R9dOlNxnfsdFr4Xjvz49Nee+2KUvfCgcP/iBzeH4aIP7PBwIuMIPyBThBzJF+IFMEX4gU4Qf\nyBThBzJV/9LdZVooUbuu7FLLJVo/ZafNJqVqC/5vPTNmhIduuuHEcPx/zlgZjr8+FrdAP/vSqYVj\nL380nhIy+sqz4XipZcfLTrndD6bspnDmBzJF+IFMEX4gU4QfyBThBzJF+IFMEX4gU/X3+aOedapv\nW2Vv1RI/B734sZPTZqsW9LOf/1S8/PWm342X3h5OfElm9sTXONx53/sKxxZtfjS+87LTaqMlzRNL\nvWs0McU7Mb4/TAnmzA9kivADmSL8QKYIP5Apwg9kivADmSL8QKYa6PMHP2+CXnr6fksuxZy6hiDo\npVtP/NjJZb9TtSeuQZh22KGFYxcufSg+VvGS5n/ywgfC8R/cckI4vmjl94sHS1xbUZbvTlybUWat\nAKnS2juFMz+QKcIPZIrwA5ki/ECmCD+QKcIPZIrwA5lK9vnNbJWkj0gacvcTWrddLeljkl5qfdpV\n7n5PW4/Yreudl9jCO7nreMlrEHpOOjYcX/LPxfPiL33npvDYPYpre/i7iT7+Pz0SjodSz3lKmee1\nbB+/W7+P90E7Z/5bJJ07ye1fcPfFrX/tBR9A10iG390flLSjhloA1KjMa/7LzOxJM1tlZnM6VhGA\nWkw1/DdJOlrSYknbJF1X9IlmtsLMBs1scETDU3w4AJ02pfC7+3Z3H3X3MUlfllS4G6O7r3T3AXcf\n6FNi0UQAtZlS+M1s/oQPL5S0oTPlAKhLO62+2ySdJelQM9sq6TOSzjKzxZJc0hZJH6+wRgAVSIbf\n3ZdNcvPNFdRSToVrvJdWsqf89B+8Ixz/1pwfFY597PkPhcc+fneij3/N98Lx0usoNHXfKd3cxw/3\nvmj/brjCD8gU4QcyRfiBTBF+IFOEH8gU4QcyVf/S3XibHcsLL5CUJN279O/C8Z1jxa2fRx94T3js\nws+vC8crVbadVmLJ857pfeGhY2++Gd/1tDg6yeXaIzVNJ+bMD2SK8AOZIvxApgg/kCnCD2SK8AOZ\nIvxApujz1yHRt73003eF4/N7p4fjjwwfVDi26C/Xh8d6omdsffFj+0hiq+vovlO98rGS26oH22SP\nvZk4NnENgY9WOQU8tRZ8Z3DmBzJF+IFMEX4gU4QfyBThBzJF+IFMEX4gU/T5a2A9cc/4+zsXhuN/\neMhPwvGB/l2FY89+7pTw2EWfjrfYTvbxy2xtXmbOu5TsxVtvcW3Jxy67LHiV24d3CGd+IFOEH8gU\n4QcyRfiBTBF+IFOEH8gU4Qcylezzm9nhkm6V9MuSxiStdPcbzWyupNslHSVpi6Sl7v6z6krdf6V6\nys99Kt4mW7c/HA73qrinfN6SeD7/d/7qfeH4Ic+Gw5qzOr5O4Mef/c3CsSPufS081h7dED94Yj5/\nzzsOKRx79i+ODY/1RDJ6Epc/jCWOX3hV8Lwlrp0IrxvZh0sn2jnz75F0ubsfJ+l0SZ8ws+MlXSlp\nrbsfI2lt62MA+4lk+N19m7s/3np/p6SNkhZIOl/S6tanrZZ0QVVFAui8fXrNb2ZHSTpZ0jpJ89x9\nmzT+A0LSYZ0uDkB12g6/mc2W9E1Jn3T3V/fhuBVmNmhmgyMankqNACrQVvjNrE/jwf+au9/Zunm7\nmc1vjc+XNDTZse6+0t0H3H2gT/2dqBlAByTDb2Ym6WZJG939+glDayQtb72/XNLdnS8PQFXME9MH\nzez9kh6S9JTGW32SdJXGX/ffIekISc9Lusjdd0T3dYjN9dNsSdma9zup5a97Zs8Kxzd/6chwfOMH\nbi4c67O4bfT6WNyz2jAST029+aUzw/EvLniwcOz2nfPDYx945bhw/KDekXD84GnF22xfO++J8Ngn\nd8dbdPcqzs2Ix+fVKxaeFo5P1Tpfq1d9R2I+8bhkn9/dH5YKG8n5JRk4QHCFH5Apwg9kivADmSL8\nQKYIP5Apwg9kKtnn76Rc+/xl7fijeNrta+ftLBz7rSPiObn/uOA/w/E3PL4OoN/6wvHISLCF9vh9\nx53oYY/nr56z4eLCsaFXZofHLro2rs1/sCkcT4qmI5dY9ntf+vyc+YFMEX4gU4QfyBThBzJF+IFM\nEX4gU4QfyBR9/jqk+rYpJb5GPSf+Wji+46Q54XhqCWobi8eDVcWTx3rJp+3Qb28uHBt9+afxwSW2\nHm9HtMZDmW3R143eR58fQIzwA5ki/ECmCD+QKcIPZIrwA5ki/ECmkkt3owNqvJZib2NPxvPO3/lk\nTYU0oFQnvmQfPyXZy490qDbO/ECmCD+QKcIPZIrwA5ki/ECmCD+QKcIPZCoZfjM73MweMLONZvZD\nM/vz1u1Xm9lPzOyJ1r/fqb5cAJ3SzkU+eyRd7u6Pm9nBkh4zs/tbY19w97+vrjwAVUmG3923SdrW\nen+nmW2UtKDqwgBUa59e85vZUZJOlrSuddNlZvakma0ys0nXgzKzFWY2aGaDIxouVSyAzmk7/GY2\nW9I3JX3S3V+VdJOkoyUt1vhvBtdNdpy7r3T3AXcf6FN/B0oG0Althd/M+jQe/K+5+52S5O7b3X3U\n3cckfVnSqdWVCaDT2vlrv0m6WdJGd79+wu3zJ3zahZI2dL48AFVp56/9Z0i6RNJTZvZE67arJC0z\ns8WSXNIWSR+vpEIAlWjnr/0Pa/LV1+/pfDkA6sIVfkCmCD+QKcIPZIrwA5ki/ECmCD+QKcIPZIrw\nA5ki/ECmCD+QKcIPZIrwA5ki/ECmCD+QKfMat482s5ck/XjCTYdKerm2AvZNt9bWrXVJ1DZVnazt\nSHf/pXY+sdbwv+3BzQbdfaCxAgLdWlu31iVR21Q1VRu/9gOZIvxAppoO/8qGHz/SrbV1a10StU1V\nI7U1+pofQHOaPvMDaEgj4Tezc83sR2b2jJld2UQNRcxsi5k91dp5eLDhWlaZ2ZCZbZhw21wzu9/M\nnm69nXSbtIZq64qdm4OdpRt97rptx+vaf+03s15JmyWdLWmrpPWSlrn7f9daSAEz2yJpwN0b7wmb\n2ZmSdkm61d1PaN32eUk73P2a1g/OOe5+RZfUdrWkXU3v3NzaUGb+xJ2lJV0g6aNq8LkL6lqqBp63\nJs78p0p6xt2fc/fdkr4h6fwG6uh67v6gpB173Xy+pNWt91dr/JundgW1dQV33+buj7fe3ynprZ2l\nG33ugroa0UT4F0h6YcLHW9VdW367pPvM7DEzW9F0MZOY19o2/a3t0w9ruJ69JXdurtNeO0t3zXM3\nlR2vO62J8E+2+083tRzOcPf3SvqwpE+0fr1Fe9raubkuk+ws3RWmuuN1pzUR/q2SDp/w8bslvdhA\nHZNy9xdbb4ck3aXu2314+1ubpLbeDjVcz891087Nk+0srS547rppx+smwr9e0jFmttDMpku6WNKa\nBup4GzOb1fpDjMxslqRz1H27D6+RtLz1/nJJdzdYyy/olp2bi3aWVsPPXbfteN3IRT6tVsYNknol\nrXL3v6m9iEmY2SKNn+2l8U1Mv95kbWZ2m6SzND7ra7ukz0j6lqQ7JB0h6XlJF7l77X94K6jtLI3/\n6vrznZvfeo1dc23vl/SQpKckjbVuvkrjr68be+6CupapgeeNK/yATHGFH5Apwg9kivADmSL8QKYI\nP5Apwg9kivADmSL8QKb+H/xpiWsGexqOAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---第1批图像中的第2张：标签为5---\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkUIp/CKFUvhFCqXwixRK4Rcp1P8BXWT2S+cm50YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---第1批图像中的第3张：标签为6---\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAEMFJREFUeJzt3W+MXNV5x/Hf4/ViYwMtVgq1wOaf\nnaiUtqTd2qigipYYOVUiQwQEv6hcCeGQhiqkUVvKm/CmEkoDlFCa4BQnRiIQouDYUlEMNaQQNXG9\ndtIAccGGGnCwbBKnxeCyrHefvthxtNg754znzJ17l+f7kazdnTP33uO7+9s7s88955i7C0A8M+ru\nAIB6EH4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0HN7OfBTrBZPltz+3nI6cEy7SU3YVa577px\n3o7xtt7SOz6S672kwvCb2XJJd0kakPTP7n5b6vmzNVdL7bKSQ74n2cz0t8EPH27kvicOkPk5q/D2\n8Wl93iqyxTd3/NyuX/ab2YCkeyR9WNL5klaa2fnd7g9Af5W8518iaZe7v+Tu70h6SNKK3nQLQNVK\nwn+GpFcnfb2n9di7mNlqMxs2s+FRjRQcDkAvlYR/qjd7x7zBc/c17j7k7kODmlVwOAC9VBL+PZIW\nTPr6TEmvlXUHQL+UhH+rpMVmdo6ZnSDpWkkbe9MtAFXrutTn7ofN7EZJmzRR6lvr7s/1rGfvJTMG\nks0+NlbZ/ktLUjYr/VbtV59I37fx0DlPtG279Prrk9vO3vTDZHvR/y1ToszuO/M91Xjh97QPiur8\n7v6opEd71BcAfcTtvUBQhB8IivADQRF+ICjCDwRF+IGg+jqeP6zSmm+upuzj3e87U+8+ZfNJyfaH\nzkkPIX1z/O22bbMf+8/ktrlae3bYber+idKhxtOgjp/DlR8IivADQRF+ICjCDwRF+IGgCD8QFKW+\nfigd/llhWemtjy1Jtm86995k+4iPJttveGV52zYfO5jcNqfSGXRzsxLnVDhrca9w5QeCIvxAUIQf\nCIrwA0ERfiAowg8ERfiBoKjz90Nhnd4GT0i2++H2tfZDV6Tr+E9+8Z8yR0/fo3Ddy8uS7bvv+EDb\ntrnjWzLHzigZ6pyrw+faS+8DaACu/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QVFGd38x2SzooaUzS\nYXcf6kWn3muydfrRd4raU/XuTXffnd408yOQG6//8t+3r+NL0tz1iVp+rlaeq7UX3D9R+j2ZDuP1\nc3pxk88fufvPerAfAH3Ey34gqNLwu6THzGybma3uRYcA9Efpy/6L3f01MztN0uNm9l/u/tTkJ7R+\nKayWpNmaU3g4AL1SdOV399daH/dLWi/pmFEk7r7G3YfcfWhQs0oOB6CHug6/mc01s5OPfC7pcknP\n9qpjAKpV8rL/dEnrbaJcM1PS1939Oz3pFYDKdR1+d39J0u/0sC/vWdmacU6mHr5pz7ZEa7qenfP+\nh/882b5o/Q+63rcNpMfjZ+flLxjPn5oDoSOl9yg0AKU+ICjCDwRF+IGgCD8QFOEHgiL8QFBM3d0P\nhUt0H7oyPf32iP9H+0Nnfr+v2v2hZPuim7ov5UlKlsSKl9jODelNnfcKlz2fLrjyA0ERfiAowg8E\nRfiBoAg/EBThB4Ii/EBQzarzVzhM0mam/6vFNecCb380Xcd/+h/vzexhsG3Ltf/9x8ktf/qFxcn2\nOSpcRtsS1xevuNaequWXLrE9DYbs5nDlB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgmlXnz9VOE7XZ\nyqeBLhn/ndl2wd++kGwfS0xBLUmH1X7/W7e+P7ltydTbkqo9b1UeO/ezlp0WfPrPB8CVHwiK8ANB\nEX4gKMIPBEX4gaAIPxAU4QeCytb5zWytpI9I2u/uF7QemyfpG5LOlrRb0jXu/ovs0Sw9rj5bi0/U\nZovH42dq6UmZseGn//vJyfb7z/pusn00U5O+7uVlbdsWfaZwPH5Oro6fOjeltfYq5+0v+X9J02K8\nfydX/q9JWn7UYzdL2uzuiyVtbn0NYBrJht/dn5J04KiHV0ha1/p8naQretwvABXr9j3/6e6+V5Ja\nH0/rXZcA9EPl9/ab2WpJqyVptuZUfTgAHer2yr/PzOZLUuvj/nZPdPc17j7k7kODNqvLwwHotW7D\nv1HSqtbnqyRt6E13APRLNvxm9qCk70v6gJntMbPrJN0maZmZ7ZS0rPU1gGkk+57f3Ve2abrsuI/m\n1c2Pb7PSbyl8NHPcknHnqbnpJX114XeT7SOZseEzla53v/4H/5NsTylez6CkFl/1XACpezdydfrM\n97TSeQr6hDv8gKAIPxAU4QeCIvxAUIQfCIrwA0E1a+ruTPklNT23j4z0ujcd23X77yfbR/z7yfY5\nM05Itl/3yiWZHryZaW+vuPRa5bDanCqH1b4HpubO4coPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0E1\nq86fqctWNRxY6mBIcOI+ghc//uXM3tN1/DfH3062v/D530y2z1H76bmLh+zmVDgsd+ddF6UPnen6\nrpXtvy/nfvOG5LaLP7M1vXOG9AKYrgg/EBThB4Ii/EBQhB8IivADQRF+IKhG1flLatKl9ezcfAC7\n7mxfcx7z7cltDytdE/7tRz6dbF/87eFke0q2jl86Jr6g3r1wy9xk+8Yz706256Y0T02J/vxV9yS3\nveyJTybb5/xL+nte5T0pvcKVHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCytb5zWytpI9I2u/uF7Qe\nu1XS9ZJebz3tFnd/tKMjJurKJbXRyuuqiXL3QGY554HM71gby9TaS8aOF463z90/8dZHfy/Z/vQ9\n97ZtG0stoS1pvPDaNMsGuz72mX+9M9n+8w3Nr+PndHJ2vyZp+RSP3+nuF7b+dRZ8AI2RDb+7PyXp\nQB/6AqCPSl5X3WhmPzaztWZ2as96BKAvug3/lySdJ+lCSXsl3d7uiWa22syGzWx4VPWtpwfg3boK\nv7vvc/cxdx+X9BVJSxLPXePuQ+4+NKj0JJkA+qer8JvZ/ElfXinp2d50B0C/dFLqe1DSpZLeZ2Z7\nJH1O0qVmdqEmCmC7JX2iwj4CqEA2/O6+coqH7+v6iCVrpqfGnpfsV8rWwxdsTtTDr03vOldTLpY6\nL4Xzy/tYevuz/ur5rvc94ula+Q2vfqjrfUvSfQufbNs2Q+l7K04cGC069nTAHX5AUIQfCIrwA0ER\nfiAowg8ERfiBoBo1dXfJNNLFS1FnSmInPvlc27arXkyXpB48d1OyfemSdLns5xUug50757vuXJps\nX7/wi8n2MW//fZkzI7N0+Wj6jtBHFj2ebFdiau8RT5fydt52frL9xBnb0oeeBkt4c+UHgiL8QFCE\nHwiK8ANBEX4gKMIPBEX4gaAaVufP/C5KLLlcPHV3ppY+fuhQ27btP/yt5LaD56X3ve7sf01vvye9\n/bnfvKFtmxWOJv7J1ellsmdZulb/v+P/17ZtjtLb5ur4uVp9auru8x/+i+S2izZsSbYXDyFvAK78\nQFCEHwiK8ANBEX4gKMIPBEX4gaAIPxBUs+r8JVNcF8wF0NGxE/cBnPlEZt9XZXadmUb60Pg7yfaX\nrv5y27bRxL0RUie18tnJ9lQdX5J+ZcaJyfaUkjq+JJ33UPv7Hxb95Q/SB8/NoZA5r9MBV34gKMIP\nBEX4gaAIPxAU4QeCIvxAUIQfCMo8U/82swWS7pf065LGJa1x97vMbJ6kb0g6W9JuSde4+y9S+zrF\n5vlSu6wH3Z5Cti6bqeMXjM8uXTNg150XJdtf/Hj7Or6UXgJ8IDNHQm758MNK17NztfaURQ98Mtl+\nxr+ljz370Rrnzi+9r6QiW3yz3vADmc5N6OTKf1jSZ939NyRdJOlTZna+pJslbXb3xZI2t74GME1k\nw+/ue919e+vzg5J2SDpD0gpJ61pPWyfpiqo6CaD3jus9v5mdLemDkrZIOt3d90oTvyAkndbrzgGo\nTsfhN7OTJH1L0k3u/sZxbLfazIbNbHhUI930EUAFOgq/mQ1qIvgPuPsjrYf3mdn8Vvt8Sfun2tbd\n17j7kLsPDSq98CKA/smG38xM0n2Sdrj7HZOaNkpa1fp8laQNve8egKp0Uuq7RNLTkp7RRKlPkm7R\nxPv+hyUtlPSKpKvd/UBqX6fYPF86cHn7J9S5rHGVy2BXLdX3TL+LlzbPyZXEUpvOTJcRfTQ91LlS\nDf15OZ5SX3Y8v7t/T2o74Lyioj2AqnGHHxAU4QeCIvxAUIQfCIrwA0ERfiCo/k/dXVL/TNWMa1wy\nOVcrzymupafOaaYenT128ZTo3X9fiuv4Tb7/oQG48gNBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUP2v\n85fU6lPTUJcumZy7/yBRM6665ltUcy4dV56Z+rvovOfuIcgdO/d/S7Vnjl35/Q8NwJUfCIrwA0ER\nfiAowg8ERfiBoAg/EBThB4Lqf52/pP5Z59z5NR671rHjVf6/s3MB1HjsqrdvAK78QFCEHwiK8ANB\nEX4gKMIPBEX4gaAIPxBUNvxmtsDMnjSzHWb2nJl9uvX4rWb2UzP7Uevfn1TfXQC90slNPoclfdbd\nt5vZyZK2mdnjrbY73f0L1XUPQFWy4Xf3vZL2tj4/aGY7JJ1RdccAVOu43vOb2dmSPihpS+uhG83s\nx2a21sxObbPNajMbNrPhUY0UdRZA73QcfjM7SdK3JN3k7m9I+pKk8yRdqIlXBrdPtZ27r3H3IXcf\nGtSsHnQZQC90FH4zG9RE8B9w90ckyd33ufuYu49L+oqkJdV1E0CvdfLXfpN0n6Qd7n7HpMfnT3ra\nlZKe7X33AFSlk7/2XyzpTyU9Y2Y/aj12i6SVZnahJJe0W9InKukhgEp08tf+70maapLyR3vfHQD9\nwh1+QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoMz7uNSw\nmb0u6eVJD71P0s/61oHj09S+NbVfEn3rVi/7dpa7/1onT+xr+I85uNmwuw/V1oGEpvatqf2S6Fu3\n6uobL/uBoAg/EFTd4V9T8/FTmtq3pvZLom/dqqVvtb7nB1Cfuq/8AGpSS/jNbLmZPW9mu8zs5jr6\n0I6Z7TazZ1orDw/X3Je1ZrbfzJ6d9Ng8M3vczHa2Pk65TFpNfWvEys2JlaVrPXdNW/G67y/7zWxA\n0guSlknaI2mrpJXu/pO+dqQNM9stacjda68Jm9kfSnpT0v3ufkHrsc9LOuDut7V+cZ7q7n/TkL7d\nKunNuldubi0oM3/yytKSrpD0Z6rx3CX6dY1qOG91XPmXSNrl7i+5+zuSHpK0ooZ+NJ67PyXpwFEP\nr5C0rvX5Ok388PRdm741grvvdfftrc8PSjqysnSt5y7Rr1rUEf4zJL066es9ataS3y7pMTPbZmar\n6+7MFE5vLZt+ZPn002ruz9GyKzf301ErSzfm3HWz4nWv1RH+qVb/aVLJ4WJ3/11JH5b0qdbLW3Sm\no5Wb+2WKlaUbodsVr3utjvDvkbRg0tdnSnqthn5Myd1fa33cL2m9mrf68L4ji6S2Pu6vuT+/1KSV\nm6daWVoNOHdNWvG6jvBvlbTYzM4xsxMkXStpYw39OIaZzW39IUZmNlfS5Wre6sMbJa1qfb5K0oYa\n+/IuTVm5ud3K0qr53DVtxetabvJplTL+QdKApLXu/nd978QUzOxcTVztpYlFTL9eZ9/M7EFJl2pi\n1Nc+SZ+T9G1JD0taKOkVSVe7e9//8Namb5dq4qXrL1duPvIeu899u0TS05KekTTeevgWTby/ru3c\nJfq1UjWcN+7wA4LiDj8gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0H9PwP1cTDDgYNbAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---第2批图像---\n",
      "---第2批图像中的第1张：标签为7---\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---第2批图像中的第2张：标签为1---\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAADrlJREFUeJzt3X2MXWW1x/Hfmul0KoWrVAQbxIsv\n1UgIVu+kamoMiiAatGhCtSZSDXE0kahREwn/SGJMqhHUm9zoLZfGahA0KtI/GhUbTTVRZCAIpZVS\nsWhtbZHihaJOZ+Ys/5hdM5Y5z3M4++3MrO8naeac/ZyXNafzm33OrGfvx9xdAOIZarsAAO0g/EBQ\nhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHglrS5JMttVFfpuVNPuXiYJlxJmmi8A89peM+mfuJkVQy\n/GZ2qaSvSBqW9H/uvil1+2VartfYRWWeMiRbkv5v8unphiqZh2V+zpg+3qg7fUfPt+37bb+ZDUv6\nH0lvlXSepA1mdl6/jwegWWU+86+RtM/dH3b345JulbSumrIA1K1M+M+W9Mc51w8U2/6NmY2b2YSZ\nTUxpssTTAahSmfDP92HvaR/w3H2zu4+5+9iIRks8HYAqlQn/AUnnzLn+AkkHy5UDoCllwn+XpFVm\n9iIzWyrpPZK2VVMWgLr13epz92kzu1rSjzTb6tvi7g9UVtliMjScHu/MJIfLtPJKtwlzrTwsWKX6\n/O6+XdL2imoB0CCm9wJBEX4gKMIPBEX4gaAIPxAU4QeCavR4/rAyffxsL34mff/UYbOlD/flkNxF\niz0/EBThB4Ii/EBQhB8IivADQRF+IChafU3IHBaba8fZyNLM/acSd878fs+0IcsejozBxZ4fCIrw\nA0ERfiAowg8ERfiBoAg/EBThB4Kiz9+E3GGxuXkAU8f7fuq9//vq5PjvL7sxOX7D0Rcnx3+yfiw5\nPrN7b3Ic7WHPDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBlerzm9l+SU9KmpE07e7ppi/mZUszx+tP\nTibHh897WdexH73ly8n7Tvmy5PiHn/Pb5Ph3L7gkOX7a7uQwWlTFJJ83uvtfKngcAA3ibT8QVNnw\nu6Qfm9ndZjZeRUEAmlH2bf9adz9oZmdKusPMfuvuO+feoPilMC5Jy3RKyacDUJVSe353P1h8PSLp\nNklr5rnNZncfc/exEY2WeToAFeo7/Ga23MxOO3FZ0iWSdlVVGIB6lXnbf5ak22z2cNQlkr7l7j+s\npCoAtes7/O7+sKRXVljL4pU5932uj5/jj/yp69jG3Vcm7/uzC25Njo9Y5rz9WLBo9QFBEX4gKMIP\nBEX4gaAIPxAU4QeC4tTdTSi5jLUtSf83dZ56quvYn//8nOR9hy5I//4/1km3IT191nEMMPb8QFCE\nHwiK8ANBEX4gKMIPBEX4gaAIPxAUff4FwDvpJb6Hn7ui69jal/8ued+yh+x6md1H5lDnsvMjysjN\nrfDp6YYqqQ97fiAowg8ERfiBoAg/EBThB4Ii/EBQhB8Iij5/Eyxz0Lun+/jZfvcZ3fv8b16xs+uY\nJP2tczw5fsrQSHL8sQvS39uKe1Z1HZvZ81Dyvtl5ADneSYylX3OfaW+OQVPY8wNBEX4gKMIPBEX4\ngaAIPxAU4QeCIvxAUNk+v5ltkXSZpCPufn6xbYWkb0s6V9J+Sevd/fH6ygwu0++eeXBf17HPbn9X\n8r7r1/93cnzU0n3+X7/3+uT42mOf6jr2wk2PJO/rU+k5CFmp180zffzMPIDFcLx/L3v+r0u69KRt\n10ja4e6rJO0orgNYQLLhd/edko6etHmdpK3F5a2SLq+4LgA16/cz/1nufkiSiq9nVlcSgCbUPrff\nzMYljUvSMp1S99MB6FG/e/7DZrZSkoqvR7rd0N03u/uYu4+NaLTPpwNQtX7Dv03SxuLyRkm3V1MO\ngKZkw29mt0j6paSXm9kBM7tK0iZJF5vZQ5IuLq4DWECyn/ndfUOXoYsqrmXxyh2vX1bifAEv/cSv\nkncdeXd6DsFUph+eO95fiW+9dB8/J3UehNw5FjIWQh8/hxl+QFCEHwiK8ANBEX4gKMIPBEX4gaA4\ndXcDbDQ9s9EnJ9MPUGap6kxLK9fKq1XmUGUbyRw2ezzTKky1WHPt11wrsOzp2AcAe34gKMIPBEX4\ngaAIPxAU4QeCIvxAUIQfCIo+fwOyffyM7GmiSywnfcrQ0uT44zN/y9w/c0hvSmb+gk9mvq/cPIHh\n7r347Gu2APr0ZbHnB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGg6PMvANnTRKeOLc/0q/+/8/fkeKk+\nfoaNpOcY+PRU+gFy8wQ6qSdf/Mfr57DnB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgsn1+M9si6TJJ\nR9z9/GLbdZI+KOnR4mbXuvv2uopc9Mr2lFPjmcd+9tCzkuO5eQDLrP+pIrUv0Z188oXfpy+rlz3/\n1yVdOs/2L7n76uIfwQcWmGz43X2npKMN1AKgQWU+819tZveZ2RYzO72yigA0ot/wf1XSSyStlnRI\n0vXdbmhm42Y2YWYTUyp3LjsA1ekr/O5+2N1n3L0j6UZJaxK33ezuY+4+NqL0gpUAmtNX+M1s5Zyr\n75S0q5pyADSll1bfLZIulHSGmR2Q9BlJF5rZakkuab+kD9VYI4AaZMPv7hvm2XxTDbUsXm0eG17y\nsYeVrn0o8+bx1Nc92n0wwDHzg4wZfkBQhB8IivADQRF+ICjCDwRF+IGgOHV3E3ItqxpbXjaanlVZ\ndgnuSU+fXvtnr7y569i7xq5K3lf37U0Ol1r6PLO8d+604IsBe34gKMIPBEX4gaAIPxAU4QeCIvxA\nUIQfCIo+/yDI9fFL9KRzvfD/+unVyfFdb/pacnzU+l/C+8HxZcnxl30w08cv06sP0MfPYc8PBEX4\ngaAIPxAU4QeCIvxAUIQfCIrwA0HR5x8EueP5a3zsZXvTvfbOmzrJ8WOd6eR48nwAQyVPzZ3r1afm\nAZTt8y+C8wGw5weCIvxAUIQfCIrwA0ERfiAowg8ERfiBoMwzx5Kb2TmSviHp+ZI6kja7+1fMbIWk\nb0s6V9J+Sevd/fHUY/2HrfDX2EUVlL3A1N0TLjNPIPP//4EHH0mOX3HqY8nxv/vxrmO5cwG8/bIr\nk+N+7+7keKn1DkaWph96qvv31aY7fYee8KM9/UD0sueflvRJd3+FpNdK+oiZnSfpGkk73H2VpB3F\ndQALRDb87n7I3e8pLj8paY+ksyWtk7S1uNlWSZfXVSSA6j2jz/xmdq6kV0m6U9JZ7n5Imv0FIenM\nqosDUJ+ew29mp0r6nqSPu/sTz+B+42Y2YWYTUyqxthqASvUUfjMb0Wzwb3b37xebD5vZymJ8paQj\n893X3Te7+5i7j40ovWgkgOZkw29mJukmSXvc/YY5Q9skbSwub5R0e/XlAahLL4f0rpX0Pkn3m9m9\nxbZrJW2S9B0zu0rSHyRdUU+Ji0DJVl6tbadMm/CGfW9Ojr8jsQS3lG7ndZQ+XNg66fFcm7oMn04v\nPb4YDunNht/dfyGp209IwKY9sDgwww8IivADQRF+ICjCDwRF+IGgCD8QFKfubkLJU3PXefioDaf7\n1Uu++dzk+Ojq9I/QpHc/tfeIZXrlJfv4qfkR2dc099w++H38HPb8QFCEHwiK8ANBEX4gKMIPBEX4\ngaAIPxAUff4mlD3uPHPsuA11n0fg0+kltHPjz9711+T45x97RXL8oyt+03VsKveyDGX2TZnXpdbT\na+fmbtR4roGqsOcHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaCyS3RXKewS3UBDql6iG8AiRPiBoAg/\nEBThB4Ii/EBQhB8IivADQWXDb2bnmNlPzWyPmT1gZh8rtl9nZn8ys3uLf2+rv1wAVenlZB7Tkj7p\n7veY2WmS7jazO4qxL7n7F+srD0BdsuF390OSDhWXnzSzPZLOrrswAPV6Rp/5zexcSa+SdGex6Woz\nu8/MtpjZ6V3uM25mE2Y2MaXJUsUCqE7P4TezUyV9T9LH3f0JSV+V9BJJqzX7zuD6+e7n7pvdfczd\nx0Y0WkHJAKrQU/jNbESzwb/Z3b8vSe5+2N1n3L0j6UZJa+orE0DVevlrv0m6SdIed79hzvaVc272\nTkm7qi8PQF16+Wv/Wknvk3S/md1bbLtW0gYzWy3JJe2X9KFaKgRQi17+2v8LSfMdH7y9+nIANIUZ\nfkBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAaXaLbzB6V\n9MicTWdI+ktjBTwzg1rboNYlUVu/qqztP939eb3csNHwP+3JzSbcfay1AhIGtbZBrUuitn61VRtv\n+4GgCD8QVNvh39zy86cMam2DWpdEbf1qpbZWP/MDaE/be34ALWkl/GZ2qZk9aGb7zOyaNmroxsz2\nm9n9xcrDEy3XssXMjpjZrjnbVpjZHWb2UPF13mXSWqptIFZuTqws3eprN2grXjf+tt/MhiXtlXSx\npAOS7pK0wd13N1pIF2a2X9KYu7feEzazN0g6Jukb7n5+se0Lko66+6biF+fp7v7pAantOknH2l65\nuVhQZuXclaUlXS7p/WrxtUvUtV4tvG5t7PnXSNrn7g+7+3FJt0pa10IdA8/dd0o6etLmdZK2Fpe3\navaHp3FdahsI7n7I3e8pLj8p6cTK0q2+dom6WtFG+M+W9Mc51w9osJb8dkk/NrO7zWy87WLmcVax\nbPqJ5dPPbLmek2VXbm7SSStLD8xr18+K11VrI/zzrf4zSC2Hte7+aklvlfSR4u0tetPTys1NmWdl\n6YHQ74rXVWsj/AcknTPn+gskHWyhjnm5+8Hi6xFJt2nwVh8+fGKR1OLrkZbr+ZdBWrl5vpWlNQCv\n3SCteN1G+O+StMrMXmRmSyW9R9K2Fup4GjNbXvwhRma2XNIlGrzVh7dJ2lhc3ijp9hZr+TeDsnJz\nt5Wl1fJrN2grXrcyyadoZXxZ0rCkLe7+ucaLmIeZvVize3tpdhHTb7VZm5ndIulCzR71dVjSZyT9\nQNJ3JL1Q0h8kXeHujf/hrUttF2r2reu/Vm4+8Rm74dpeL+nnku6X1Ck2X6vZz9etvXaJujaohdeN\nGX5AUMzwA4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8Q1D8B1u1zjgcacIYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---第2批图像中的第3张：标签为3---\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "H,W=28,28\n",
    "\n",
    "files=tf.train.match_filenames_once(os.path.curdir+\"/data/\"+\"data*.tfrecord\")\n",
    "\n",
    "# 创建TFRecordReader对象\n",
    "reader=tf.TFRecordReader()\n",
    "records_queue=tf.train.string_input_producer(files,num_epochs=2)\n",
    "_,serialized_example=reader.read(records_queue)\n",
    "\n",
    "# 解析文件中的图像及其对应的标签\n",
    "features=tf.parse_single_example(\n",
    "    serialized_example,\n",
    "    features={\n",
    "        'img_raw':tf.FixedLenFeature([],tf.string),\n",
    "        'label':tf.FixedLenFeature([],tf.int64),\n",
    "    }\n",
    ")\n",
    "\n",
    "# 解码二进制数据\n",
    "img_raw=features['img_raw']\n",
    "img_raw=tf.decode_raw(img_raw,tf.uint8)\n",
    "\n",
    "# 转换成图片\n",
    "img=tf.reshape(img_raw,[H,W])\n",
    "\n",
    "# 标签\n",
    "label=features['label']\n",
    "label=tf.cast(label,tf.int64)\n",
    "\n",
    "# 每次从文件中读取3张图片\n",
    "BatchSize=3\n",
    "img,label=tf.train.shuffle_batch([img,label],BatchSize,1000+3*BatchSize,1000)\n",
    "\n",
    "session=tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "session.run(tf.local_variables_initializer())\n",
    "\n",
    "coord=tf.train.Coordinator()\n",
    "threads=tf.train.start_queue_runners(sess=session,coord=coord)\n",
    "print(session.run(files))\n",
    "\n",
    "# 循环2次解析文件流中的数据\n",
    "for i in range(2):\n",
    "    print(\"---第%(num)d批图像---\"%{'num':i+1})\n",
    "    imgs,labels=session.run([img,label])\n",
    "    \n",
    "    for j in range(BatchSize):\n",
    "        print(\"---第%(num)d批图像中的第%(index)d张：标签为%(l)d---\"%{\"num\":i+1,\"index\":j+1,\"l\":labels[j]})\n",
    "        \n",
    "        plt.imshow(imgs[j,:,:])\n",
    "        plt.show()\n",
    "\n",
    "coord.request_stop()\n",
    "coord.join(threads)\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 3.建立模型\n",
    "全连接神经网络的输入层都是一维张量，而图像是高维张量(灰色图像是二维张量，彩色图像是三维张量)。如果把图像转换为一个全连接神经网络的输入，直接将高维张量拉伸为一个一维张量即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-13.0977354    4.13779497   5.97057438  -7.29600286 -11.34489727\n",
      "   -4.86154842  -2.60884142   0.13025093  -1.98705816  -0.21878564]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 构建全连接神经网络\n",
    "def net(tensor):\n",
    "    # 输入层，隐含层，输出层的神经元个数\n",
    "    I,H1,O=784,200,10\n",
    "    # 第1层的权重矩阵和偏置\n",
    "    w1=tf.random_normal([I,H1],0,1,tf.float32)\n",
    "    b1=tf.random_normal([H1],0,1,tf.float32)\n",
    "    # 隐含层的结果，采用sigmoid激活函数\n",
    "    l1=tf.matmul(tensor,w1)+b1\n",
    "    sigma1=tf.nn.sigmoid(l1)\n",
    "    \n",
    "    # 第2层的权重矩阵和偏置\n",
    "    w2=tf.random_normal([H1,O],0,1,tf.float32)\n",
    "    b2=tf.random_normal([O],0,1,tf.float32)\n",
    "    \n",
    "    # 输出层的结果\n",
    "    l2=tf.matmul(sigma1,w2)+b2\n",
    "    return l2\n",
    "\n",
    "# 读取图片文件\n",
    "image=tf.read_file(\"0.jpg\",\"r\")\n",
    "\n",
    "# 将图片文件解码为Tensor\n",
    "image_tensor=tf.image.decode_jpeg(image)\n",
    "\n",
    "# 图像张量的形状\n",
    "length=tf.size(image_tensor) # length=28*28\n",
    "\n",
    "# 改变形状，拉伸为1个一维张量，按行存储\n",
    "t=tf.reshape(image_tensor,[1,length])\n",
    "\n",
    "# 数据类型转换，转换为float32类型\n",
    "t=tf.cast(t,tf.float32)\n",
    "\n",
    "# 标准化处理\n",
    "t=t/255.0\n",
    "\n",
    "output=net(t)\n",
    "session=tf.Session()\n",
    "\n",
    "print(session.run(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "最理想的情况是经过全连接神经网络的输出结果_y(即全连接神经网络输出层的值)与人工分类的结果y相等"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 三.损失函数与训练模型\n",
    "对于分类问题的损失函数，常用的是sigmoid交叉熵和softmax交叉熵"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### 1.sigmoid损失函数\n",
    "Tensorflow通过函数sigmoid_cross_entropy_with_logits(labels,logits,name)实现sigmoid交叉熵，其中labels代表人工分类标签，是一个N行C列的二维张量，代表N个样本的标签，每一行代表一个样本的分类标签，logits代表输出层的结果，与labels的尺寸相同，每一行代表一个样本经过全连接神经后的输出值，利用求和函数reduce_sum对函数sigmoid_cross_entropy_logits返回的结果求和，其结果为sigmoid交叉熵损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.7825\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 输出层的值\n",
    "logits=tf.constant(\n",
    "    [\n",
    "        [-13.0977354,4.13779497,5.97057438,-7.29600286,-11.34489727,-4.86154842,-2.60884142,0.13025093,-1.98705816,-0.21878564]\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 人工分类的标签\n",
    "labels=tf.constant([[1,0,0,0,0,0,0,0,0,0]],tf.float32)\n",
    "\n",
    "# sigmoid交叉熵\n",
    "entroy=tf.nn.sigmoid_cross_entropy_with_logits(logits=logits,labels=labels)\n",
    "\n",
    "# 损失值\n",
    "loss=tf.reduce_sum(entroy)\n",
    "\n",
    "session=tf.Session()\n",
    "print(session.run(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.softmax损失函数\n",
    "softmax计算原理\n",
    "Tensorflow通过函数softmax(logits,axis=None,name=None,dim=None)实现softmax处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.19999999  0.5         0.29999998]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# 输入张量\n",
    "t=tf.constant([2,5,3],tf.float32)\n",
    "x=tf.log(t)\n",
    "# softmax处理\n",
    "s=tf.nn.softmax(x,0)\n",
    "# 创建会话\n",
    "session=tf.Session()\n",
    "\n",
    "print(session.run(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "函数tf.nn.softmax可以处理多维张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.21194157  0.57611692  0.21194157]\n",
      " [ 0.33333334  0.33333334  0.33333334]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 输入张量\n",
    "x=tf.constant(\n",
    "    [\n",
    "        [1,2,1],\n",
    "        [2,2,2]\n",
    "    ]\n",
    "    ,tf.float32\n",
    ")\n",
    "\n",
    "# 分别对每一行(沿\"1\"方向)进行softmax处理\n",
    "s=tf.nn.softmax(x,1)\n",
    "\n",
    "session=tf.Session()\n",
    "\n",
    "print(session.run(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "softmax交叉熵及softmax损失函数\n",
    "利用Tensorflow的求和函数reduce_sum和函数tf.nn.softmax定义softmax损失函数为tf.reduce_sum(-y*tf.nn.softmax(_y,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.25979\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 假设_y为全连接神经网络的输出(输出层有3个神经元)\n",
    "_y=tf.constant(\n",
    "    [\n",
    "        [0,2,-3],\n",
    "        [4,-5,6]\n",
    "    ]\n",
    "    ,tf.float32\n",
    ")\n",
    "\n",
    "# 人工分类结果\n",
    "y=tf.constant(\n",
    "    [\n",
    "        [1,0,0],\n",
    "        [0,0,1]]\n",
    "    ,tf.float32\n",
    ")\n",
    "\n",
    "# softmax熵\n",
    "_y_softmax=tf.nn.softmax(_y)\n",
    "entroy=tf.reduce_sum(-y*tf.log(_y_softmax),1)\n",
    "\n",
    "# loss损失函数\n",
    "loss=tf.reduce_sum(entroy)\n",
    "\n",
    "session=tf.Session()\n",
    "\n",
    "print(session.run(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上代码实现中，使用了乘法运算符*和函数tf.nn.softmax实现softmax熵，Tensorflow将这两个运算封装成了一个函数softmax_cross_entroy_with_logits_v2,\n",
    "即tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(logits,labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.25979\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# 假设_y为全连接神经网络的输出(输出层有3个神经元)\n",
    "_y=tf.constant([[0,2,-3],[4,-5,6]],tf.float32)\n",
    "\n",
    "# 人工分类结果\n",
    "y=tf.constant([[1,0,0],[0,0,1]],tf.float32)\n",
    "\n",
    "# softmax熵\n",
    "entroy=tf.nn.softmax_cross_entropy_with_logits(logits=_y,labels=y)\n",
    "\n",
    "# loss损失函数\n",
    "loss=tf.reduce_sum(entroy)\n",
    "\n",
    "session=tf.Session()\n",
    "\n",
    "print(session.run(loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.训练和评估模型\n",
    "直到现在我们已经掌握了：\n",
    "1.从TFRecord中解析数据\n",
    "2.构建全连接神经网络\n",
    "3.构造损失函数\n",
    "4.梯度下降法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfRangeError",
     "evalue": "RandomShuffleQueue '_2_shuffle_batch/random_shuffle_queue' is closed and has insufficient elements (requested 3, current size 1)\n\t [[Node: shuffle_batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, shuffle_batch/n)]]\n\nCaused by op 'shuffle_batch', defined at:\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-33348cd51422>\", line 44, in <module>\n    imgs,labels_onehot=tf.train.shuffle_batch([img,label_onehot],BatchSize,1000+3*BatchSize,1000)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tensorflow\\python\\training\\input.py\", line 1217, in shuffle_batch\n    name=name)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tensorflow\\python\\training\\input.py\", line 788, in _shuffle_batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 457, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 946, in _queue_dequeue_many_v2\n    timeout_ms=timeout_ms, name=name)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nOutOfRangeError (see above for traceback): RandomShuffleQueue '_2_shuffle_batch/random_shuffle_queue' is closed and has insufficient elements (requested 3, current size 1)\n\t [[Node: shuffle_batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, shuffle_batch/n)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32mE:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\mytensorflow\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[1;34m()\u001b[0m\n\u001b[0;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[0;32m    467\u001b[0m   \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: RandomShuffleQueue '_2_shuffle_batch/random_shuffle_queue' is closed and has insufficient elements (requested 3, current size 1)\n\t [[Node: shuffle_batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, shuffle_batch/n)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-33348cd51422>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mBatchSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mimgs_arr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlables_onehot_arr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels_onehot\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopti\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mimgs_arr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlables_onehot_arr\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[0mcoord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest_stop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mE:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1150\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOutOfRangeError\u001b[0m: RandomShuffleQueue '_2_shuffle_batch/random_shuffle_queue' is closed and has insufficient elements (requested 3, current size 1)\n\t [[Node: shuffle_batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, shuffle_batch/n)]]\n\nCaused by op 'shuffle_batch', defined at:\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-11-33348cd51422>\", line 44, in <module>\n    imgs,labels_onehot=tf.train.shuffle_batch([img,label_onehot],BatchSize,1000+3*BatchSize,1000)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tensorflow\\python\\training\\input.py\", line 1217, in shuffle_batch\n    name=name)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tensorflow\\python\\training\\input.py\", line 788, in _shuffle_batch\n    dequeued = queue.dequeue_many(batch_size, name=name)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 457, in dequeue_many\n    self._queue_ref, n=n, component_types=self._dtypes, name=name)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 946, in _queue_dequeue_many_v2\n    timeout_ms=timeout_ms, name=name)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 767, in apply_op\n    op_def=op_def)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 2506, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"E:\\Anaconda\\envs\\mytensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1269, in __init__\n    self._traceback = _extract_stack()\n\nOutOfRangeError (see above for traceback): RandomShuffleQueue '_2_shuffle_batch/random_shuffle_queue' is closed and has insufficient elements (requested 3, current size 1)\n\t [[Node: shuffle_batch = QueueDequeueManyV2[component_types=[DT_FLOAT, DT_FLOAT], timeout_ms=-1, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](shuffle_batch/random_shuffle_queue, shuffle_batch/n)]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "# 占位符\n",
    "x=tf.placeholder(tf.float32,[None,28*28])\n",
    "labels=tf.placeholder(tf.float32,[None,10])\n",
    "\n",
    "# 第1步：解析数据\n",
    "nums=33 # 所有训练样本的个数\n",
    "\n",
    "# 得到文件夹./data/下的所有tfrecord文件\n",
    "files=tf.train.match_filenames_once(os.path.curdir+\"/data/\"+\"data*.tfrecord\")\n",
    "\n",
    "# 创建TFRecordReader对象\n",
    "num_epochs=1000\n",
    "reader=tf.TFRecordReader()\n",
    "records_queue=tf.train.string_input_producer(files,num_epochs=num_epochs)\n",
    "_,serialized_example=reader.read(records_queue)\n",
    "\n",
    "# 解析文件中的图像及其对应的标签\n",
    "features=tf.parse_single_example(\n",
    "        serialized_example,\n",
    "        features={\n",
    "                'img_raw':tf.FixedLenFeature([],tf.string),\n",
    "                'label':tf.FixedLenFeature([],tf.int64),\n",
    "                }\n",
    "                                 )\n",
    "\n",
    "\n",
    "# 解码二进制数据\n",
    "img_raw=features['img_raw']\n",
    "img_raw=tf.decode_raw(img_raw,tf.uint8)\n",
    "img=tf.reshape(img_raw,[28*28])\n",
    "img=tf.cast(img,tf.float32)\n",
    "img=img/255.0\n",
    "\n",
    "# 标签\n",
    "label=features['label']\n",
    "label=tf.cast(label,tf.int64)\n",
    "label_onehot=tf.one_hot(label,10,dtype=tf.float32)\n",
    "\n",
    "# 每次从文件中读取3张图片\n",
    "BatchSize =3\n",
    "imgs,labels_onehot=tf.train.shuffle_batch([img,label_onehot],BatchSize,1000+3*BatchSize,1000)\n",
    "\n",
    "\n",
    "# 第2步：构建全连接神经网络\n",
    "# 输入层，隐含层，输出层的神经元个数\n",
    "I,H1,O=784,200,10\n",
    "\n",
    "# 输入层到隐含层的权重矩阵和偏置\n",
    "w1=tf.Variable(tf.random_normal([I,H1],0,1,tf.float32),dtype=tf.float32,name='w1')\n",
    "b1=tf.Variable(tf.random_normal([H1],0,1,tf.float32),dtype=tf.float32,name='b1')\n",
    "\n",
    "# 隐含层的结果，采用sigmoid激活函数\n",
    "l1=tf.matmul(x,w1)+b1\n",
    "sigma1=tf.nn.sigmoid(l1)\n",
    "\n",
    "# 第2层的权重及偏置\n",
    "w2=tf.Variable(tf.random_normal([H1,O],0,1,tf.float32),dtype=tf.float32,name='w2')\n",
    "b2=tf.Variable(tf.random_normal([O],0,1,tf.float32),dtype=tf.float32,name='b2')\n",
    "\n",
    "# 输出层的结果\n",
    "logits=tf.matmul(sigma1,w2)+b2\n",
    "\n",
    "# 第3步：构造损失函数\n",
    "loss=tf.reduce_sum(tf.nn.softmax_cross_entropy_with_logits(labels=labels_onehot,logits=logits))\n",
    "\n",
    "# 第4步：梯度下降\n",
    "opti=tf.train.AdamOptimizer(0.001,0.9,0.999,1e-8).minimize(loss)\n",
    "\n",
    "session=tf.Session()\n",
    "session.run(tf.global_variables_initializer())\n",
    "session.run(tf.local_variables_initializer())\n",
    "\n",
    "coord=tf.train.Coordinator()\n",
    "threads=tf.train.start_queue_runners(sess=session,coord=coord)\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    for n in range(int(nums/BatchSize)):\n",
    "        imgs_arr,lables_onehot_arr=session.run([imgs,labels_onehot])\n",
    "        session.run(opti,feed_dict={x:imgs_arr,labels:lables_onehot_arr})\n",
    "        \n",
    "coord.request_stop()\n",
    "coord.join(threads)\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上代码中函数tf.train.shuffle_batch和tf.train.AdamOptimizer的组合使用其实就实现了用随机梯度下降法处理函数的最小值"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
